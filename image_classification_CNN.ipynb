{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_classification_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPh0bG/Pzi7rEzC0OOt+CDu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lostinrepo/Deep-Learning/blob/master/image_classification_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy7_Drfs5nCB",
        "colab_type": "text"
      },
      "source": [
        "Image Classification using **CNN** (**Convolution** **Neural** **Network**)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAjiwV-0ok6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "8e4ceb4a-6067-4808-fbb9-f005a54bdcb0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efkwNn1opB3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBYlgS5VpXcY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "41cf2fa6-dff7-4fc8-df8c-b23ad96a6fc4"
      },
      "source": [
        "#data preprocessing\n",
        "train_data = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "train_data = train_data.flow_from_directory('/content/drive/My Drive/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8032 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-uNaiGsp3_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7f33c7a8-0e6c-4974-a802-45f32583b87c"
      },
      "source": [
        "test_data = ImageDataGenerator(rescale = 1./255)\n",
        "test_data = test_data.flow_from_directory('/content/drive/My Drive/dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOZPSEK1qkS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D,Dense\n",
        "from tensorflow.keras.layers import Flatten\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLA5E-Qir_wg",
        "colab_type": "text"
      },
      "source": [
        "First **Convolution** Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B66i7fpcqxXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adding first convolution layer\n",
        "cnn=Sequential()\n",
        "cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3])) \n",
        "cnn.add(MaxPool2D(pool_size=2, strides=2)) #pooling"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUqP_Ed_sJiv",
        "colab_type": "text"
      },
      "source": [
        "Second **Convolution** Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6d2cSpNq793",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(MaxPool2D(pool_size=2, strides=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e65fYQNGsYad",
        "colab_type": "text"
      },
      "source": [
        "**Flattening**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbVX-BlRsX4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9EVtSnTtFE8",
        "colab_type": "text"
      },
      "source": [
        "Full Connection (**Dense** Layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OJM-f8XtAeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.add(Dense(128, activation='relu'))\n",
        "cnn.add(Dense(1, activation='sigmoid')) #output layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO62obsmtXEi",
        "colab_type": "text"
      },
      "source": [
        "Compiling cnn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x32gLMrtbya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX2wr8j3tkOw",
        "colab_type": "text"
      },
      "source": [
        "**Fitting** on Training data and **evaluationg** on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbNVvQlPtrLg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "outputId": "dfcde111-d95d-403f-ee44-ac1537622c5a"
      },
      "source": [
        "cnn.fit(x = train_data, validation_data = test_data, epochs = 25)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "251/251 [==============================] - 50s 200ms/step - loss: 0.1871 - accuracy: 0.9237 - val_loss: 0.5962 - val_accuracy: 0.7935\n",
            "Epoch 2/25\n",
            "251/251 [==============================] - 50s 199ms/step - loss: 0.1600 - accuracy: 0.9394 - val_loss: 0.6126 - val_accuracy: 0.7970\n",
            "Epoch 3/25\n",
            "251/251 [==============================] - 50s 200ms/step - loss: 0.1558 - accuracy: 0.9400 - val_loss: 0.7327 - val_accuracy: 0.7815\n",
            "Epoch 4/25\n",
            "251/251 [==============================] - 51s 205ms/step - loss: 0.1439 - accuracy: 0.9448 - val_loss: 0.7555 - val_accuracy: 0.7795\n",
            "Epoch 5/25\n",
            "251/251 [==============================] - 52s 208ms/step - loss: 0.1436 - accuracy: 0.9472 - val_loss: 0.6325 - val_accuracy: 0.8015\n",
            "Epoch 6/25\n",
            "251/251 [==============================] - 52s 209ms/step - loss: 0.1342 - accuracy: 0.9480 - val_loss: 0.6661 - val_accuracy: 0.7985\n",
            "Epoch 7/25\n",
            "251/251 [==============================] - 54s 214ms/step - loss: 0.1265 - accuracy: 0.9533 - val_loss: 0.6830 - val_accuracy: 0.7945\n",
            "Epoch 8/25\n",
            "251/251 [==============================] - 53s 210ms/step - loss: 0.1275 - accuracy: 0.9514 - val_loss: 0.7130 - val_accuracy: 0.7890\n",
            "Epoch 9/25\n",
            "251/251 [==============================] - 52s 208ms/step - loss: 0.1110 - accuracy: 0.9582 - val_loss: 0.7051 - val_accuracy: 0.7945\n",
            "Epoch 10/25\n",
            "251/251 [==============================] - 51s 204ms/step - loss: 0.1155 - accuracy: 0.9562 - val_loss: 0.7527 - val_accuracy: 0.7870\n",
            "Epoch 11/25\n",
            "251/251 [==============================] - 50s 199ms/step - loss: 0.0998 - accuracy: 0.9625 - val_loss: 0.8947 - val_accuracy: 0.7860\n",
            "Epoch 12/25\n",
            "251/251 [==============================] - 50s 200ms/step - loss: 0.1083 - accuracy: 0.9615 - val_loss: 0.8385 - val_accuracy: 0.7785\n",
            "Epoch 13/25\n",
            "251/251 [==============================] - 51s 204ms/step - loss: 0.1017 - accuracy: 0.9615 - val_loss: 0.7794 - val_accuracy: 0.7870\n",
            "Epoch 14/25\n",
            "251/251 [==============================] - 51s 203ms/step - loss: 0.0787 - accuracy: 0.9704 - val_loss: 0.7994 - val_accuracy: 0.7980\n",
            "Epoch 15/25\n",
            "251/251 [==============================] - 50s 201ms/step - loss: 0.0917 - accuracy: 0.9653 - val_loss: 0.7945 - val_accuracy: 0.7940\n",
            "Epoch 16/25\n",
            "251/251 [==============================] - 50s 199ms/step - loss: 0.0777 - accuracy: 0.9721 - val_loss: 0.8440 - val_accuracy: 0.7930\n",
            "Epoch 17/25\n",
            "251/251 [==============================] - 51s 202ms/step - loss: 0.0898 - accuracy: 0.9681 - val_loss: 0.7666 - val_accuracy: 0.7995\n",
            "Epoch 18/25\n",
            "251/251 [==============================] - 51s 204ms/step - loss: 0.0838 - accuracy: 0.9690 - val_loss: 0.8461 - val_accuracy: 0.7875\n",
            "Epoch 19/25\n",
            "251/251 [==============================] - 52s 205ms/step - loss: 0.0839 - accuracy: 0.9696 - val_loss: 0.9114 - val_accuracy: 0.7750\n",
            "Epoch 20/25\n",
            "251/251 [==============================] - 51s 202ms/step - loss: 0.0772 - accuracy: 0.9707 - val_loss: 0.8903 - val_accuracy: 0.8040\n",
            "Epoch 21/25\n",
            "251/251 [==============================] - 51s 203ms/step - loss: 0.0701 - accuracy: 0.9739 - val_loss: 0.8293 - val_accuracy: 0.8030\n",
            "Epoch 22/25\n",
            "251/251 [==============================] - 51s 204ms/step - loss: 0.0651 - accuracy: 0.9761 - val_loss: 0.9216 - val_accuracy: 0.7930\n",
            "Epoch 23/25\n",
            "251/251 [==============================] - 51s 204ms/step - loss: 0.0629 - accuracy: 0.9775 - val_loss: 0.9004 - val_accuracy: 0.7935\n",
            "Epoch 24/25\n",
            "251/251 [==============================] - 51s 204ms/step - loss: 0.0600 - accuracy: 0.9778 - val_loss: 0.9029 - val_accuracy: 0.7950\n",
            "Epoch 25/25\n",
            "251/251 [==============================] - 52s 207ms/step - loss: 0.0770 - accuracy: 0.9716 - val_loss: 0.9063 - val_accuracy: 0.7895\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa268004a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTpCE3K7F-oW",
        "colab_type": "text"
      },
      "source": [
        "Accuracy - 97 %"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOlqo56JuDpp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1db440a3-c4c3-44d2-f3dd-bfc98bb66f58"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq_sarS6u9rs",
        "colab_type": "text"
      },
      "source": [
        "Predicting on Single Image "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx-5c0U_uAh_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "02ccb331-5a62-4b10-9514-8df95f83aaec"
      },
      "source": [
        "\n",
        "pred_img = image.load_img('/content/drive/My Drive/dataset/unknown_1.jpg', target_size = (64, 64))\n",
        "pred_img = image.img_to_array(pred_img)\n",
        "pred_img = np.expand_dims(pred_img, axis = 0)\n",
        "result = cnn.predict(pred_img)\n",
        "train_data.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZeT06gmmGEhW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a15b7d0e-9943-4545-a8b8-0f51ebeca08f"
      },
      "source": [
        "\n",
        "pred_img = image.load_img('/content/drive/My Drive/dataset/unknown_2.jpg', target_size = (64, 64))\n",
        "pred_img = image.img_to_array(pred_img)\n",
        "pred_img = np.expand_dims(pred_img, axis = 0)\n",
        "result = cnn.predict(pred_img)\n",
        "train_data.class_indices\n",
        "if result[0][0] == 1:\n",
        "  prediction = 'dog'\n",
        "else:\n",
        "  prediction = 'cat'\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U-lzP1CGIvM",
        "colab_type": "text"
      },
      "source": [
        "In both cases we got correct predictions"
      ]
    }
  ]
}